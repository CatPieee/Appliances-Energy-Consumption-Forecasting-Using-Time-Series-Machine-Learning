{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ff7ec5",
   "metadata": {},
   "source": [
    "# Time Series Machine Learning Experimentation (Simplified)\n",
    "\n",
    "This notebook implements traditional time series forecasting models for appliances energy consumption prediction.\n",
    "Models included: Prophet and SARIMA (seasonal ARIMA)\n",
    "\n",
    "Note: LSTM and other deep learning models have been moved to the deep learning models directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import_packages",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987877fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series models\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f0db1",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ba70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv('../data/energydata_complete_cleaned.csv', parse_dates=['date'], index_col='date')\n",
    "df.sort_index(inplace=True)\n",
    "print('Data shape: ', df.shape)\n",
    "print('Date range:', df.index.min(), 'to', df.index.max())\n",
    "\n",
    "# For time series models, we'll use chronological split\n",
    "train_size = int(len(df) * 0.7)\n",
    "train_df = df.iloc[:train_size].copy()\n",
    "test_df = df.iloc[train_size:].copy()\n",
    "\n",
    "print('Training data shape: ', train_df.shape)\n",
    "print('Testing data shape: ', test_df.shape)\n",
    "print('Training period:', train_df.index.min(), 'to', train_df.index.max())\n",
    "print('Testing period:', test_df.index.min(), 'to', test_df.index.max())\n",
    "\n",
    "# Prepare Prophet format data\n",
    "prophet_train = train_df.reset_index().rename(columns={'date': 'ds', 'Appliances': 'y'})[['ds', 'y']]\n",
    "prophet_test = test_df.reset_index().rename(columns={'date': 'ds', 'Appliances': 'y'})[['ds', 'y']]\n",
    "\n",
    "print('\\nProphet training data shape:', prophet_train.shape)\n",
    "print('Prophet testing data shape:', prophet_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dictionary\n",
    "model_results = {}\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Calculate evaluation metrics for a model\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    model_results[model_name] = results\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RÂ²: {r2:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prophet_model_section",
   "metadata": {},
   "source": [
    "## 1. Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prophet_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Prophet model...\")\n",
    "\n",
    "# Initialize Prophet model\n",
    "prophet_model = Prophet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=False,  # no yearly seasonality due to limited data period\n",
    "    changepoint_prior_scale=0.05,\n",
    "    seasonality_prior_scale=10.0,\n",
    "    holidays_prior_scale=10.0,\n",
    "    seasonality_mode='multiplicative'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "prophet_model.fit(prophet_train)\n",
    "\n",
    "# Make predictions\n",
    "prophet_forecast = prophet_model.predict(prophet_test[['ds']])\n",
    "prophet_predictions = prophet_forecast['yhat'].values\n",
    "\n",
    "# Evaluate Prophet model\n",
    "prophet_results = evaluate_model(prophet_test['y'].values, prophet_predictions, 'Prophet')\n",
    "\n",
    "print(\"Prophet model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prophet_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet results visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Time series plot\n",
    "axes[0, 0].plot(prophet_test['ds'], prophet_test['y'], label='Actual', alpha=0.7)\n",
    "axes[0, 0].plot(prophet_test['ds'], prophet_predictions, label='Predicted', alpha=0.7)\n",
    "axes[0, 0].set_title('Prophet: Actual vs Predicted')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Energy Consumption (Wh)')\n",
",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot\n",
    "axes[0, 1].scatter(prophet_test['y'], prophet_predictions, alpha=0.5, s=1)\n",
    "axes[0, 1].plot([prophet_test['y'].min(), prophet_test['y'].max()], \n",
    "                [prophet_test['y'].min(), prophet_test['y'].max()], 'r--', lw=2)\n",
    "axes[0, 1].set_title('Prophet: Predicted vs Actual')\n",
    "axes[0, 1].set_xlabel('Actual Energy Consumption (Wh)')\n",
    "axes[0, 1].set_ylabel('Predicted Energy Consumption (Wh)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = prophet_test['y'] - prophet_predictions\n",
    "axes[1, 0].hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Prophet: Residuals Distribution')\n",
    "axes[1, 0].set_xlabel('Residuals (Wh)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals over time\n",
    "axes[1, 1].scatter(prophet_test['ds'], residuals, alpha=0.5, s=1)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].set_title('Prophet: Residuals Over Time')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Residuals (Wh)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/prediction_plots/prophet_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arima_section",
   "metadata": {},
   "source": [
    "## 2. SARIMA Model (Seasonal ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stationarity_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stationarity of the time series\n",
    "def check_stationarity(timeseries, title):\n",
    "    \"\"\"Check if a time series is stationary using Augmented Dickey-Fuller test\"\"\"\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    \n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Perform Augmented Dickey-Fuller test\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    \n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "    if dftest[1] \u003c= 0.05:\n",
    "        print(\"Series is stationary\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Series is not stationary\")\n",
    "        return False\n",
    "\n",
    "# Check original series\n",
    "appliances_series = train_df['Appliances']\n",
    "is_stationary = check_stationarity(appliances_series, \"Original Appliances Series\")\n",
    "\n",
    "# If not stationary, apply differencing\n",
    "if not is_stationary:\n",
    "    appliances_diff = appliances_series.diff().dropna()\n",
    "    print(\"\\nAfter first differencing:\")\n",
    "    is_stationary_diff = check_stationarity(appliances_diff, \"First Differenced Series\")\n",
    "    \n",
    "    if is_stationary_diff:\n",
    "        d_param = 1\n",
    "        working_series = appliances_diff\n",
    "    else:\n",
    "        appliances_diff2 = appliances_diff.diff().dropna()\n",
    "        print(\"\\nAfter second differencing:\")\n",
    "        check_stationarity(appliances_diff2, \"Second Differenced Series\")\n",
    "        d_param = 2\n",
    "        working_series = appliances_diff2\n",
    "else:\n",
    "    d_param = 0\n",
    "    working_series = appliances_series\n",
    "\n",
    "print(f\"\\nUsing d parameter: {d_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arima_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training SARIMA model...\")\n",
    "\n",
    "# Fit SARIMA model\n",
    "# Note: Given our 4-month dataset, yearly seasonality is not relevant\n",
    "# We'll focus on daily patterns (48 half-hour periods per day)\n",
    "try:\n",
    "    # Try ARIMA first (non-seasonal)\n",
    "    arima_model = ARIMA(train_df['Appliances'], order=(2, d_param, 2))\n",
    "    arima_fitted = arima_model.fit()\n",
    "    \n",
    "    print(\"ARIMA model summary:\")\n",
    "    print(arima_fitted.summary())\n",
    "    \n",
    "    # Make predictions\n",
    "    arima_forecast = arima_fitted.forecast(steps=len(test_df))\n",
    "    arima_predictions = arima_forecast.values\n",
    "    \n",
    "    # Ensure predictions are non-negative (energy consumption can't be negative)\n",
    "    arima_predictions = np.maximum(arima_predictions, 0)\n",
    "    \n",
    "    # Evaluate ARIMA model\n",
    "    arima_results = evaluate_model(test_df['Appliances'].values, arima_predictions, 'SARIMA')\n",
    "    \n",
    "    print(\"SARIMA model training completed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error training ARIMA model: {e}\")\n",
    "    print(\"Trying simpler ARIMA(1,1,1) model...\")\n",
    "    \n",
    "    try:\n",
    "        arima_model = ARIMA(train_df['Appliances'], order=(1, 1, 1))\n",
    "        arima_fitted = arima_model.fit()\n",
    "        \n",
    "        arima_forecast = arima_fitted.forecast(steps=len(test_df))\n",
    "        arima_predictions = arima_forecast.values\n",
    "        arima_predictions = np.maximum(arima_predictions, 0)\n",
    "        \n",
    "        arima_results = evaluate_model(test_df['Appliances'].values, arima_predictions, 'SARIMA')\n",
    "        print(\"SARIMA(1,1,1) model training completed!\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"Error with ARIMA(1,1,1): {e2}\")\n",
    "        arima_predictions = np.full(len(test_df), train_df['Appliances'].mean())\n",
    "        arima_results = evaluate_model(test_df['Appliances'].values, arima_predictions, 'SARIMA (Mean Baseline)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arima_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA results visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Time series plot\n",
    "axes[0, 0].plot(test_df.index, test_df['Appliances'], label='Actual', alpha=0.7)\n",
    "axes[0, 0].plot(test_df.index, arima_predictions, label='Predicted', alpha=0.7)\n",
    "axes[0, 0].set_title('SARIMA: Actual vs Predicted')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Energy Consumption (Wh)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot\n",
    "axes[0, 1].scatter(test_df['Appliances'], arima_predictions, alpha=0.5, s=1)\n",
    "axes[0, 1].plot([test_df['Appliances'].min(), test_df['Appliances'].max()], \n",
    "                [test_df['Appliances'].min(), test_df['Appliances'].max()], 'r--', lw=2)\n",
    "axes[0, 1].set_title('SARIMA: Predicted vs Actual')\n",
    "axes[0, 1].set_xlabel('Actual Energy Consumption (Wh)')\n",
    "axes[0, 1].set_ylabel('Predicted Energy Consumption (Wh)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = test_df['Appliances'] - arima_predictions\n",
    "axes[1, 0].hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('SARIMA: Residuals Distribution')\n",
    "axes[1, 0].set_xlabel('Residuals (Wh)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals over time\n",
    "axes[1, 1].scatter(test_df.index, residuals, alpha=0.5, s=1)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].set_title('SARIMA: Residuals Over Time')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Residuals (Wh)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/prediction_plots/sarima_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results_comparison",
   "metadata": {},
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "results_comparison = pd.DataFrame({\n",
    "    model: {\n",
    "        'MSE': metrics['MSE'],\n",
    "        'RMSE': metrics['RMSE'],\n",
    "        'MAE': metrics['MAE'],\n",
    "        'R2': metrics['R2']\n",
    "    }\n",
    "    for model, metrics in model_results.items()\n",
    "}).T.round(4)\n",
    "\n",
    "print(\"Time Series Models Performance Comparison:\")\n",
    "print(results_comparison)\n",
    "\n",
    "# Find best model\n",
    "best_r2_model = max(model_results.items(), key=lambda x: x[1]['R2'])[0]\n",
    "best_mse_model = min(model_results.items(), key=lambda x: x[1]['MSE'])[0]\n",
    "best_mae_model = min(model_results.items(), key=lambda x: x[1]['MAE'])[0]\n",
    "\n",
    "print(f\"\\nBest Model Summary \" + \"=\" * 40)\n",
    "print(f\"  Best RÂ² Model:  {best_r2_model} (RÂ² = {model_results[best_r2_model]['R2']:.4f})\")\n",
    "print(f\"  Best MSE Model: {best_mse_model} (MSE = {model_results[best_mse_model]['MSE']:.2f})\")\n",
    "print(f\"  Best MAE Model: {best_mae_model} (MAE = {model_results[best_mae_model]['MAE']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This simplified time series analysis focuses on two traditional time series models:\n",
    "\n",
    "1. **Prophet**: A modern time series forecasting tool that handles seasonality well\n",
    "2. **SARIMA**: Seasonal ARIMA model for capturing autoregressive patterns\n",
    "\n",
    "For deep learning models (RNN, LSTM, Transformer), please refer to the `src/deep_learning_models/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}